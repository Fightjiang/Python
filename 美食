import requests
import re
from requests.exceptions import RequestException
from multiprocessing import Pool
import time

# 获取网页请求数据
def get_one_page(url):
    try:
        headers = {
            'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'
        }
        reponse = requests.get(url,headers = headers)
        if reponse.status_code == 200:
            return reponse.text
        return None
    except RequestException:
        return None
        

#解析网页结构
def parse_one_page(url):
    print(url) # 看看爬虫爬去到第几页了？
    html = get_one_page(url)
    pattern = re.compile(r'<div class="listtyle1">.*?'
                         r'<a target.*?href="(.*?)".*?title="(.*?)" class="big">.*?'
                         r'<img class="img".*?src="(.*?)">.*?</div>',re.S)
    items = re.findall(pattern,html)
    time.sleep(1) # 采集完一页休息一秒
    # 下载图片到本地
    for item in items:
        # 将 菜名, 做法, 图片 保存到本地
        with open('/Users/lec/Desktop/456.txt','a') as f:
            f.write("{},,{},{}\n".format(item[1],item[2],item[0]))

        #  wb+ 以二进制读写模式打开
        #  将图片下载到本地
        with open('C:/Users/lec/Desktop/img/' + item[1] + '.png','wb+') as f:
            f.write(requests.get(item[2]).content)

def main(offset):
    url = 'https://www.meishij.net/china-food/caixi/xiangcai/?&page='+str(offset)
    parse_one_page(url)

if __name__ =='__main__':
    pool = Pool()
    pool.map(main,[i for i in range(1,50)])
